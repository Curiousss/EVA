{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Curiousss/EVA/blob/master/Assignment13/ResNet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbbGcfMCnjtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.metrics import binary_accuracy\n",
        "from keras import backend as K\n",
        "from keras.callbacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMNeXuwvn2bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CyclicLR(Callback):\n",
        "    \n",
        "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
        " \n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.base_m = base_m\n",
        "        self.max_m = max_m\n",
        "        self.cyclical_momentum = cyclical_momentum\n",
        "        self.step_size = step_size\n",
        "        \n",
        "        self.clr_iterations = 0.\n",
        "        self.cm_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "        \n",
        "    def clr(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
        "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
        "    \n",
        "    def cm(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            \n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
        "            return self.max_m\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "        if self.cyclical_momentum == True:\n",
        "            if self.clr_iterations == 0:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            else:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "                \n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            K.set_value(self.model.optimizer.momentum, self.cm())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbOXhMgdn3KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_QMGG3Un6Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_rows, img_cols,img_channels =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCFutwhVn9p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    idx = np.where(train_labels[:]==i)[0]\n",
        "    features_idx = train_features[idx,::]\n",
        "    img_num = np.random.randint(features_idx.shape[0])\n",
        "    im = features_idx[img_num]\n",
        "    ax.set_title(class_names[i])\n",
        "    plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm7kWY7AoDCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLcMOCBdoG5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQZakuxBoJod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/yu4u/cutout-random-erasing\n",
        "!cp cutout-random-erasing/* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkCBxMuloPhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_features\n",
        "X_test = test_features\n",
        "y_train = train_labels\n",
        "y_test = test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh0S9uH5o9gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ResNet Model\n",
        "def AddResNetBlock(model, inputs, skip, convsize, stride, padding):\n",
        "\n",
        "  return resnet_block\n",
        "\n",
        "x = Input()\n",
        "x = Conv2D(64,7,2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "x = AddResNetBlock(x, input=x.output)\n",
        "ResNetmodel = Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDxOs6zgoSdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random_eraser import get_random_eraser\n",
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                             featurewise_center=True, featurewise_std_normalization=True,\n",
        "                             preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=False))\n",
        "\n",
        "testgen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "num_samples = X_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge8qxNPxoYSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "# Compile the model\n",
        "sgd = SGD(lr=0.000001, momentum=0.9, nesterov=True)\n",
        "model1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eo1pWm7obU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "max_lr = 0.5\n",
        "base_lr = max_lr/10000\n",
        "max_m = 0.98\n",
        "base_m = 0.85\n",
        "\n",
        "cyclical_momentum = True\n",
        "augment = True\n",
        "cycles = 2.35\n",
        "\n",
        "iterations = round(num_samples/batch_size*epochs)\n",
        "iterations = list(range(0,iterations+1))\n",
        "step_size = len(iterations)/(cycles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkfqJ3qmoem8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr =  CyclicLR(base_lr=base_lr,\n",
        "                max_lr=max_lr,\n",
        "                step_size=step_size,\n",
        "                max_m=max_m,\n",
        "                base_m=base_m,\n",
        "                cyclical_momentum=cyclical_momentum)\n",
        "    \n",
        "callbacks = [clr,\n",
        "            ModelCheckpoint(filepath='ResNet_best_model.h5', monitor='val_loss',mode='min',verbose=1,save_best_only=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC5xtpmtohBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hist = ResNet18model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data=testgen.flow(X_test, y_test, batch_size=batch_size), epochs=50, callbacks=callbacks, validation_steps=(X_test.shape[0]//batch_size), steps_per_epoch=num_samples// batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}